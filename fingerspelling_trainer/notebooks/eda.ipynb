{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "46d7c8c3",
            "metadata": {},
            "source": [
                "### Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "90ca90c2",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "from collections import Counter\n",
                "import itertools\n",
                "import logging\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib as mpl\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "import joblib\n",
                "import hydra\n",
                "import os\n",
                "\n",
                "\n",
                "from matplotlib import font_manager\n",
                "\n",
                "\n",
                "from keypoint_extraction_pipeline.schemas.annotation import AnnotationRecord\n",
                "from keypoint_extraction_pipeline.savers.json_saver import JSONSaver\n",
                "from fingerspelling_trainer.training.utils.alphabets import Alphabet\n",
                "\n",
                "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
                "plt.rcParams[\"axes.grid\"] = True\n",
                "logging.basicConfig(level=logging.INFO)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22c3c607",
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = Path(\"/home/gts/projects/lruanova/projects/signamed/data/LSE/transformed/\")\n",
                "\n",
                "# Scaler stats\n",
                "scaler_vel = joblib.load(os.path.join(DATA_DIR,\"vel.pkl\"))\n",
                "scaler_kp  = joblib.load(os.path.join(DATA_DIR,\"kp.pkl\"))\n",
                "\n",
                "print(\"Scaler (wrist-vel):\")\n",
                "print(\"Mean (vx, vy, vz):\", scaler_vel.mean_)\n",
                "print(\"Std (vx, vy, vz):\", scaler_vel.scale_)\n",
                "print(\"\\nScaler (kps):\")\n",
                "print(\"Mean (x, y, z):\", scaler_kp.mean_)\n",
                "print(\"Std (x, y, z):\", scaler_kp.scale_)\n",
                "\n",
                "# Alphabet\n",
                "with hydra.initialize(version_base=\"1.3\", config_path=\"../config\"):\n",
                "    cfg = hydra.compose(config_name=\"config\")\n",
                "\n",
                "ALPHABET: Alphabet = hydra.utils.instantiate(\n",
                "            cfg.dataset.alphabet\n",
                "        )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d9012389",
            "metadata": {},
            "source": [
                "**Helpers**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fcc835cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_annotation(path: Path) -> AnnotationRecord:\n",
                "    return JSONSaver.load_record(path)\n",
                "\n",
                "def duration_frames(record: AnnotationRecord) -> int:\n",
                "    return len(record.frames)\n",
                "\n",
                "def raw_label(record: AnnotationRecord) -> str:\n",
                "    return record.metadata.label or \"\"\n",
                "\n",
                "def signing_hand(record: AnnotationRecord) -> str:\n",
                "    return (record.metadata.handness or \"\").lower()  # \"left\"/\"right\"/\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d5134bcf",
            "metadata": {},
            "source": [
                "**Load all samples**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae259bd0",
            "metadata": {},
            "outputs": [],
            "source": [
                "splits = [\"train\", \"validation\", \"test\"]\n",
                "file_lists = {s: sorted((DATA_DIR / s).glob(\"*.json\")) for s in splits}\n",
                "\n",
                "for s, fl in file_lists.items():\n",
                "    print(f\"{s:<10}: {len(fl):5d} muestras – {sum(f.stat().st_size for f in fl)/1e6:.1f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6bc83ff0",
            "metadata": {},
            "source": [
                "### Duration of annotations (in frames)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "938c411b",
            "metadata": {},
            "source": [
                "**Plot - frames per sample distribution**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0ca7c2e",
            "metadata": {},
            "outputs": [],
            "source": [
                "records = []\n",
                "for split in [\"train\",\"validation\",\"test\"]:\n",
                "    for json_path in sorted((DATA_DIR/ split).glob(\"*.json\")):\n",
                "        rec: AnnotationRecord = JSONSaver.load_record(json_path)\n",
                "        n_frames = len(rec.frames)\n",
                "        lbl = rec.metadata.label or \"\"\n",
                "        records.append({\n",
                "            \"file\": str(json_path),\n",
                "            \"split\": split,\n",
                "            \"frames\": n_frames,\n",
                "            \"label\": lbl\n",
                "        })\n",
                "\n",
                "dur_df = pd.DataFrame(records)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "04189581",
            "metadata": {},
            "outputs": [],
            "source": [
                "# save\n",
                "dur_df.to_parquet(\"dur_df.parquet\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "381605f4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# load\n",
                "dur_df = pd.read_parquet(\"dur_df.parquet\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2312d2f0",
            "metadata": {},
            "outputs": [],
            "source": [
                "font_dir = \"/home/gts/projects/lruanova/misc/fonts/times_new_roman\"\n",
                "for f in font_manager.findSystemFonts(fontpaths=font_dir):\n",
                "    font_manager.fontManager.addfont(f)\n",
                "mpl.rcParams['font.family'] = 'Times New Roman'\n",
                "mpl.rcParams['pdf.fonttype'] = 42\n",
                "mpl.rcParams['ps.fonttype'] = 42\n",
                "\n",
                "# prepare data\n",
                "dur_df[\"len_label\"] = dur_df[\"label\"].str.len().replace(0, np.nan)\n",
                "dur_df[\"frames_per_char\"] = dur_df[\"frames\"] / dur_df[\"len_label\"]\n",
                "\n",
                "def extract_person_id(path_str: str) -> str:\n",
                "    fname = Path(path_str).name\n",
                "    parts = fname.split(\"_\")\n",
                "    if len(parts) >= 2:\n",
                "        return parts[1]  # p1, p2, ...\n",
                "    else:\n",
                "        return \"unknown\"\n",
                "\n",
                "dur_df[\"person_id\"] = dur_df[\"file\"].apply(extract_person_id)\n",
                "dur_df = dur_df[dur_df[\"person_id\"] != \"unknown\"].copy()\n",
                "\n",
                "# plot func\n",
                "def plot_speed_by_person_ieee(split_name: str, save_path: str):\n",
                "    fig, ax = plt.subplots(figsize=(7.1, 3))\n",
                "    subdf = dur_df[dur_df[\"split\"] == split_name].copy()\n",
                "    order = (subdf.groupby(\"person_id\")[\"frames_per_char\"]\n",
                "                   .median().sort_values().index.tolist())\n",
                "    sns.boxplot(\n",
                "        data=subdf,\n",
                "        x=\"person_id\",\n",
                "        y=\"frames_per_char\",\n",
                "        order=order,\n",
                "        palette=\"tab10\",\n",
                "        fliersize=2,\n",
                "        ax=ax\n",
                "    )\n",
                "    ax.set_yscale(\"log\")\n",
                "    ax.set_yticks([1, 10])\n",
                "    ax.set_yticklabels([r'$10^0$', r'$10^1$'], fontsize=10)\n",
                "    ax.set_xlabel(\"Signer ID\", fontsize=12, labelpad=4)\n",
                "    ax.set_ylabel(\"Frames per character\", fontsize=12, labelpad=4)\n",
                "    ax.set_title(\"\")\n",
                "    ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
                "    ax.tick_params(axis='y', labelsize=10)\n",
                "    fig.tight_layout()\n",
                "    fig.patch.set_facecolor('white')\n",
                "    ax.set_facecolor('white')\n",
                "    fig.savefig(save_path, dpi=600, bbox_inches='tight', facecolor='white')\n",
                "    plt.show()\n",
                "\n",
                "plot_speed_by_person_ieee(\"train\", \"fig1.png\")\n",
                "plot_speed_by_person_ieee(\"validation\", \"fig2.png\")\n",
                "plot_speed_by_person_ieee(\"test\", \"fig3.png\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7b84241e",
            "metadata": {},
            "source": [
                "**Annotations per signer**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1fcad213",
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_person_number(path_str):\n",
                "    fname = Path(path_str).name\n",
                "    parts = fname.split(\"_\")\n",
                "    if len(parts) >= 2 and parts[1].startswith(\"p\"):\n",
                "        return int(parts[1][1:])  # p1 → 1\n",
                "    return np.nan\n",
                "\n",
                "dur_df[\"person_number\"] = dur_df[\"file\"].apply(extract_person_number)\n",
                "dur_df_clean = dur_df.dropna(subset=[\"person_number\"]).copy()\n",
                "dur_df_clean[\"person_number\"] = dur_df_clean[\"person_number\"].astype(int)\n",
                "\n",
                "annots_per_signer = dur_df_clean[\"person_number\"].value_counts().sort_index()\n",
                "\n",
                "plt.figure(figsize=(15, 5))\n",
                "sns.barplot(\n",
                "    x=annots_per_signer.index.astype(str),\n",
                "    y=annots_per_signer.values,\n",
                "    color=\"skyblue\"\n",
                ")\n",
                "plt.xlabel(\"Signer ID\", fontsize=16, labelpad=10)\n",
                "plt.ylabel(\"Number of annotations\", fontsize=16, labelpad=10)\n",
                "plt.title(\"Annotations per signer\", fontsize=18, pad=15)\n",
                "plt.xticks(fontsize=12, rotation=90)\n",
                "plt.yticks(fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fb416abb",
            "metadata": {},
            "source": [
                "--------------"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b528eaa6",
            "metadata": {},
            "source": [
                "**Stats**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4e3a779b",
            "metadata": {},
            "outputs": [],
            "source": [
                "stats = dur_df.groupby(\"split\")[\"frames\"].describe()\n",
                "stats"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b5ccb73d",
            "metadata": {},
            "source": [
                "**Suggested intervals**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "83ed7df8",
            "metadata": {},
            "outputs": [],
            "source": [
                "q1, q3 = dur_df[\"frames\"].quantile([0.25, 0.75])\n",
                "iqr = q3 - q1\n",
                "low_lim, up_lim = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
                "print(f\"Suggested intervals: <{low_lim:.1f} | >{up_lim:.1f} frames\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0b72810e",
            "metadata": {},
            "source": [
                "**Top shortest and largest sequences**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ce7f0e7a",
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.set_option('display.max_colwidth', None)\n",
                "shortest = dur_df.nsmallest(50, \"frames\")[[\"file\", \"frames\"]]\n",
                "longest  = dur_df.nlargest(50, \"frames\")[[\"file\", \"frames\"]]\n",
                "print(\"\\nTop 50 shortest:\")\n",
                "display(shortest)\n",
                "print(\"\\nTop 50 longest:\")\n",
                "display(longest)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d7d0e584",
            "metadata": {},
            "source": [
                "### Label analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "90af648a",
            "metadata": {},
            "source": [
                "**Load labels into dataframe**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "21ad4519",
            "metadata": {},
            "outputs": [],
            "source": [
                "labels = []\n",
                "for split, files in file_lists.items():\n",
                "    for f in tqdm(files, desc=f\"Labels {split}\"):\n",
                "        rec = load_annotation(f)\n",
                "        labels.append({\n",
                "            \"split\": split,\n",
                "            \"file\": f,\n",
                "            \"label\": raw_label(rec).upper().strip(),\n",
                "        })\n",
                "label_df = pd.DataFrame(labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c18d04b2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib as mpl\n",
                "from matplotlib import font_manager\n",
                "from fingerspelling_trainer.data.transformations.encode_label import EncodeLabel\n",
                "\n",
                "font_dir = \"/home/gts/projects/lruanova/misc/fonts/times_new_roman\"\n",
                "for f in font_manager.findSystemFonts(fontpaths=font_dir):\n",
                "    font_manager.fontManager.addfont(f)\n",
                "mpl.rcParams['font.family'] = 'Times New Roman'\n",
                "mpl.rcParams['pdf.fonttype'] = 42\n",
                "mpl.rcParams['ps.fonttype'] = 42\n",
                "\n",
                "# Prepare data\n",
                "label_formatter = EncodeLabel(\n",
                "    alphabet=ALPHABET,\n",
                "    remove_non_alphabetic=False,\n",
                "    collapse_repeated=False,\n",
                "    include_spaces=False,\n",
                "    validate=False\n",
                ")\n",
                "\n",
                "df_sym_processed = label_df.copy()\n",
                "df_sym_processed['formatted_label'] = df_sym_processed['label'].apply(lambda x: label_formatter._format_label(x))\n",
                "df_sym_processed['encoded_tokens'] = df_sym_processed['formatted_label'].apply(lambda x: ALPHABET.encode_label(x))\n",
                "df_sym_processed['symbol_list'] = df_sym_processed['encoded_tokens'].apply(\n",
                "    lambda tokens: [ALPHABET.NUM_TO_LETTER.get(token, f\"UNKNOWN_TOKEN_{token}\") for token in tokens]\n",
                ")\n",
                "\n",
                "df_exploded_symbols = df_sym_processed[['split', 'symbol_list']].explode('symbol_list')\n",
                "sym_counts_processed = (\n",
                "    df_exploded_symbols.dropna(subset=['symbol_list'])\n",
                "    .groupby(['symbol_list', 'split'])\n",
                "    .size()\n",
                "    .reset_index(name='count')\n",
                ")\n",
                "sym_pivot_processed = (\n",
                "    sym_counts_processed\n",
                "    .pivot(index='symbol_list', columns='split', values='count')\n",
                "    .fillna(0).astype(int)\n",
                ")\n",
                "\n",
                "# order (desc)\n",
                "sym_pivot_processed['total'] = sym_pivot_processed.sum(axis=1)\n",
                "sym_pivot_processed = sym_pivot_processed.sort_values(by='total', ascending=False)\n",
                "sym_pivot_processed = sym_pivot_processed.drop(columns='total')\n",
                "\n",
                "# Visualize\n",
                "fig, ax = plt.subplots(figsize=(11, 5))\n",
                "sym_pivot_processed.plot(\n",
                "    kind='bar',\n",
                "    stacked=True,\n",
                "    ax=ax,\n",
                "    color=['#3B5BA4', '#F59C3F', '#B4B4B4']\n",
                ")\n",
                "ax.set_ylabel('Number of occurrences', fontsize=16, labelpad=6)\n",
                "ax.set_xlabel('Symbol', fontsize=16, labelpad=6)\n",
                "ax.set_title('')\n",
                "ax.tick_params(axis='x', labelrotation=60, labelsize=13)\n",
                "ax.tick_params(axis='y', labelsize=13)\n",
                "ax.legend(title='Split', fontsize=12, title_fontsize=13)\n",
                "fig.tight_layout()\n",
                "fig.patch.set_facecolor('white')\n",
                "ax.set_facecolor('white')\n",
                "fig.savefig('test.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aae9a8d5",
            "metadata": {},
            "source": [
                "**Empty labels, with only 1 symbol and top 50 shortest**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8458f19f",
            "metadata": {},
            "outputs": [],
            "source": [
                "label_df['len']=label_df.label.str.len()\n",
                "empty=label_df[label_df.len==0]\n",
                "single=label_df[label_df.len==1]\n",
                "print(f'Empty: {len(empty)}')\n",
                "print(f'Unique symbol: {len(single)}')\n",
                "print('Top 50 shortest:')\n",
                "display(label_df.nsmallest(50,'len')[['file','label','len']])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "251232f0",
            "metadata": {},
            "source": [
                "**Symbols ordered by frequency**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cbecc356",
            "metadata": {},
            "outputs": [],
            "source": [
                "sym_counter = Counter(itertools.chain.from_iterable(label_df.label))\n",
                "sym_df = pd.DataFrame(sym_counter.items(), columns=['symbol', 'count'])\n",
                "sym_df = sym_df.sort_values('count', ascending=False).assign(freq=lambda d: d['count'] / d['count'].sum())\n",
                "plt.figure(figsize=(10, 12))\n",
                "sns.barplot(data=sym_df.head(100), y='symbol', x='count')\n",
                "plt.title('Symbols order by frequency')\n",
                "plt.yticks(fontsize=14)\n",
                "plt.xticks(np.arange(0, sym_df['count'].max() + 250, 250))\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6945142b",
            "metadata": {},
            "source": [
                "**Pairs ordered by frequency**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0fa6fda6",
            "metadata": {},
            "outputs": [],
            "source": [
                "pairs = [label[i:i+2] for label in label_df.label for i in range(len(label)-1)]\n",
                "bi_counter = Counter(pairs)\n",
                "bi_df = (pd.DataFrame(bi_counter.items(), columns=[\"digraph\", \"count\"])\\\n",
                "         .sort_values(\"count\", ascending=False))\n",
                "\n",
                "plt.figure(figsize=(10, 20))\n",
                "sns.barplot(data=bi_df.head(100), y='digraph', x='count')\n",
                "plt.title('Symbols order by frequency')\n",
                "plt.yticks(fontsize=14)\n",
                "plt.xticks(np.arange(0, sym_df['count'].max() + 250, 250))\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e0a09820",
            "metadata": {},
            "source": [
                "**Label distribution per partition**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a102dbff",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sym = label_df.assign(symbol_list=label_df.label.apply(list)).explode('symbol_list')\n",
                "sym_counts = df_sym.groupby(['symbol_list','split']).size().reset_index(name='count')\n",
                "sym_pivot = sym_counts.pivot(index='symbol_list', columns='split', values='count').fillna(0).astype(int)\n",
                "\n",
                "display(sym_pivot)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "72b1af7c",
            "metadata": {},
            "source": [
                "### Left/Right handed distribution"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63d36a2e",
            "metadata": {},
            "source": [
                "**Load data**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "83a06779",
            "metadata": {},
            "outputs": [],
            "source": [
                "hand_stats = []\n",
                "for split, files in file_lists.items():\n",
                "    for f in files:\n",
                "        rec = load_annotation(f)\n",
                "        hand_stats.append({\n",
                "            \"split\": split,\n",
                "            \"file\": f,\n",
                "            \"hand\": signing_hand(rec) or \"unknown\",\n",
                "        })\n",
                "hand_df = pd.DataFrame(hand_stats)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c9126a0c",
            "metadata": {},
            "source": [
                "**Count left vs right-handed**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.countplot(data=hand_df, x=\"hand\", hue=\"split\")\n",
                "plt.title(\"Dist left / right handed\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
